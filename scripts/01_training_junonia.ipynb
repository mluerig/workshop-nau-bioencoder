{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e5fec3",
   "metadata": {},
   "source": [
    "# Training a BioEncoder-model on butterflies\n",
    "\n",
    "This notebook demonstrates the complete two-stage workflow for training a BioEncoder model on Junonia butterfly images. Stage 1 learns discriminative features using deep metric learning, while Stage 2 fine-tunes a classification head for species prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec639f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bioencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba0e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r\"D:\\git-repos\\mluerig\\workshop-nau-bioencoder\")\n",
    "os.chdir(r\"/scratch/mdl458/workshop-nau-bioencoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc0f92",
   "metadata": {},
   "source": [
    "### Initialize BioEncoder Workspace\n",
    "\n",
    "Create the project directory structure for this training run. The `root_dir` variable points to where all training outputs (models, logs, plots) will be saved, the `run_name` parameter allows you to organize multiple experiments<>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bb0bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found root_dir: bioencoder_wd\n",
      "Given your Python WD (/home/mlurig/git-repos/workshop-nau-bioencoder), the current BioEncoder run directory will be:\n",
      "- /home/mlurig/git-repos/workshop-nau-bioencoder/bioencoder_wd/v1\n"
     ]
    }
   ],
   "source": [
    "bioencoder.configure(root_dir=bioencoder_wd, run_name=\"v1\", create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71aa8a",
   "metadata": {},
   "source": [
    "### Split Dataset into Train/Val sets\n",
    "\n",
    "Automatically partition the Junonia dorsal images into training, validation, and test sets. The `max_ratio=10` parameter ensures no class has more than 10x the samples of the smallest class, helping to balance training. The `random_seed` ensures reproducibility. Use `help(bioencoder.split_dataset)` to see additional options like `val_percent` for custom split proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.configure(root_dir=bioencoder_wd, run_name=\"v1\", create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71aa8a",
   "metadata": {},
   "source": [
    "### Split Dataset into Train/Val sets\n",
    "\n",
    "Automatically partition the Junonia dorsal images into training, validation, and test sets. The `max_ratio=10` parameter ensures no class has more than 10x the samples of the smallest class, helping to balance training. The `random_seed` ensures reproducibility. Use `help(bioencoder.split_dataset)` to see additional options like `val_percent` for custom split proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8b0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(bioencoder.split_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47324993",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.split_dataset(image_dir=\"../data_raw/junonia_dorsal\", max_ratio=10, random_seed=42, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a6314",
   "metadata": {},
   "source": [
    "### Stage 1 Training\n",
    "\n",
    "Train the feature extraction backbone using metric learning (e.g., triplet or contrastive loss). This stage learns to embed visually similar specimens close together in feature space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.train(root_dir=r\"bioencoder_wd\", run_name=\"v1\", config_path=r\"configs/train_stage1.yml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab9880",
   "metadata": {},
   "source": [
    "### Stochastic Weight Averaging (SWA)\n",
    "\n",
    "Average the model weights from the last several training epochs to create a more robust final model. SWA typically improves generalization by finding flatter minima in the loss landscape, leading to better performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.swa(config_path=r\"configs/swa_stage1.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f814426",
   "metadata": {},
   "source": [
    "### Visualize Stage 1 Results\n",
    "\n",
    "Generate interactive plots including PCA/t-SNE embeddings to visualize how the model organizes specimens in feature space. These visualizations help assess whether the learned embeddings capture meaningful phenotypic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddcd2c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: using swa of first stage\n",
      "tSNE: using perplexity 30 and random state 42\n",
      "tSNE: using perplexity 30 and random state 42\n"
     ]
    }
   ],
   "source": [
    "bioencoder.interactive_plots(config_path=r\"configs/plot_stage1.yml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6dd5b",
   "metadata": {},
   "source": [
    "### Stage 2 Training\n",
    "\n",
    "Fine-tune the pre-trained encoder by adding and training a classification head. This stage uses the rich feature representations learned in Stage 1 but optimizes for direct class prediction using cross-entropy loss. The frozen or partially frozen backbone helps prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cc69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.train(root_dir=r\"bioencoder_wd\", run_name=\"v1\", config_path=r\"configs/train_stage2.yml\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bae1a95",
   "metadata": {},
   "source": [
    "### SWA for Stage 2\n",
    "\n",
    "Average weights from Stage 2 training checkpoints to stabilize the final classification model. This ensures the classifier benefits from the same generalization improvements as the feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.swa(config_path=r\"configs/swa_stage2.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa1d0bb",
   "metadata": {},
   "source": [
    "### Explore the Final Model\n",
    "\n",
    "Launch the interactive model explorer to analyze predictions, visualize attention maps, and identify which image regions the model uses for classification. This tool helps discover morphological traits of importance and validates that the model learns biologically meaningful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c2b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.model_explorer(config_path=r\"configs/explore_stage2.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9c733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioencoder-env",
   "display_name": "bioencoder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
