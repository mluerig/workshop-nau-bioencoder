{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e5fec3",
   "metadata": {},
   "source": [
    "# Analyses of training-outcomes\n",
    "\n",
    "Evaluate the BioEncoder model from Notebook 1: run inference on validation images, plot confusion matrices, and inspect embeddings via PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec639f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bioencoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(r\"D:\\git-repos\\mluerig\\workshop-nau-bioencoder\")\n",
    "os.chdir(r\"/home/mlurig/git-repos/workshop-nau-bioencoder\")\n",
    "# os.chdir(r\"/scratch/mdl458/workshop-nau-bioencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4658dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioencoder.configure(root_dir=r\"bioencoder_wd\", run_name=\"v1\", create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc0f92",
   "metadata": {},
   "source": [
    "### Run inference and collect predictions\n",
    "\n",
    "Run `bioencoder.inference` on every image in the validation set and collect predictions in a nested dictionary for later analysis.\n",
    "\n",
    "- Source directory: `bioencoder_wd/data/v1/val/`\n",
    "- Output structure: `results[true_class][image_name] -> predicted_class` (string)\n",
    "- Config used: `configs/inference.yml`\n",
    "\n",
    "These predictions will be used to compute both raw and normalized confusion matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b83635",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "img_dir = r\"bioencoder_wd/data/v1/val/\"\n",
    "for class_name in os.listdir(img_dir):\n",
    "    class_dir = os.path.join(img_dir, class_name)\n",
    "    results[class_name] = dict()\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        path = os.path.join(class_dir, image_name)\n",
    "        result = bioencoder.inference(config_path=\"configs/inference.yml\", image=path)\n",
    "        print(f\"class: {class_name}; prediction: {result}\")\n",
    "        results[class_name][image_name] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f5588",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Compute a confusion matrix across all predictions in `results`. We assume `results[true_class][image_name]` is the predicted class (string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build y_true and y_pred from `results`\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for true_class, file_map in results.items():\n",
    "    for _img_name, predicted_class in file_map.items():\n",
    "        y_true.append(true_class)\n",
    "        y_pred.append(predicted_class)\n",
    "\n",
    "labels = sorted(set(y_true) | set(y_pred))\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(max(6, len(labels)*0.5), max(6, len(labels)*0.5)))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(ax=ax, xticks_rotation=90, cmap=\"Blues\", colorbar=False)\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot row-wise normalized confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(max(6, len(labels)*0.5), max(6, len(labels)*0.5)))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=labels,\n",
    "    normalize=\"true\",\n",
    "    display_labels=labels,\n",
    "    cmap=\"Blues\",\n",
    "    ax=ax,\n",
    "    xticks_rotation=90,\n",
    "    colorbar=False,\n",
    "    values_format=\".1f\",  # show one decimal for normalized values\n",
    ")\n",
    "ax.set_title(\"Confusion Matrix (Normalized per True Class)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1728734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = pd.read_csv(r\"data/embeddings_v1.csv\")\n",
    "df_feat = pd.read_csv(r\"data_raw/data_feat_junonia.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4c554",
   "metadata": {},
   "source": [
    "### PCA on embeddings with supplementary variables\n",
    "\n",
    "We will use manual (hand-crafted) features extracted with the [phenopype package](https://www.phenopype.org/). These include, for instance, basic statistical descriptors (e.g., mean pixel intensity and variance), Discrete Fourier Transform (DFT)â€“based shape/texture descriptors, and color clustering metrics (e.g., estimated number of dominant colors). We treat these as supplementary variables to help interpret patterns in the learned embedding space.\n",
    "\n",
    "Here we merge embeddings (`df_emb`) with features (`df_feat`) via `df_emb.image_name == df_feat.mask_name`, run PCA on the embedding vectors, and relate features to PCs by projecting them into the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize embeddings (main variables)\n",
    "X_main = df_emb.iloc[:,3:].to_numpy(dtype=float)\n",
    "X_main_scaled = StandardScaler().fit_transform(X_main)\n",
    "\n",
    "# PCA on standardized embeddings (keep first 2 for plotting/relations)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pc_scores = pca.fit_transform(X_main_scaled)\n",
    "\n",
    "# Prepare plot DataFrame with identifiers\n",
    "df_plot = df_emb.iloc[:,:3].copy()\n",
    "df_plot[[\"Dim1\", \"Dim2\"]] = pc_scores\n",
    "\n",
    "# supporting variables: image features\n",
    "df_supp = df_feat[df_feat[\"mask_name\"].isin(df_emb[\"image_name\"])].copy()\n",
    "feature_cols = df_supp.columns[1:].tolist()\n",
    "X_support = df_supp[feature_cols].to_numpy(dtype=float)\n",
    "X_support_scaled = StandardScaler().fit_transform(X_support)\n",
    "\n",
    "# Align PC rows to df_supp order via mask_name/image_name\n",
    "pc_df = pd.DataFrame(pc_scores, index=df_emb[\"image_name\"], columns=[\"Dim1\", \"Dim2\"])\n",
    "pc12_aligned = pc_df.loc[df_supp[\"mask_name\"]].to_numpy(dtype=float)\n",
    "pc12_scaled = StandardScaler().fit_transform(pc12_aligned)\n",
    "\n",
    "# Supplementary variable loadings as correlations with PC axes\n",
    "supp_loadings = (pc12_scaled.T @ X_support_scaled) / (X_support_scaled.shape[0] - 1)\n",
    "df_supp_loadings = pd.DataFrame(\n",
    "    supp_loadings.T, columns=[\"Dim1\", \"Dim2\"], index=feature_cols\n",
    ").reset_index().rename(columns={\"index\": \"feature\"})\n",
    "\n",
    "# Report variance explained for the two components\n",
    "var_explained = pca.explained_variance_ratio_[:2]\n",
    "print(f\"Explained variance: PC1={var_explained[0]:.2%}, PC2={var_explained[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supp_loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Color by fixed categorical column 'class_str' using discrete jet colormap\n",
    "ser = df_emb[\"class_str\"].astype(str)\n",
    "cats = pd.Categorical(ser)\n",
    "labels = list(cats.categories)\n",
    "n = max(1, len(labels))\n",
    "cmap = plt.cm.get_cmap(\"jet\", n)\n",
    "idx = cats.codes\n",
    "ax.scatter(df_plot['Dim1'], df_plot['Dim2'], c=idx, cmap=cmap, s=30, alpha=0.85, edgecolors='none')\n",
    "handles = [mpl.patches.Patch(color=cmap(i), label=lab) for i, lab in enumerate(labels)]\n",
    "ax.legend(handles=handles, title=\"class_str\", bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "# Axes lines and aspect ratio\n",
    "ax.axhline(0, color='lightgray', lw=1)\n",
    "ax.axvline(0, color='lightgray', lw=1)\n",
    "ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "amod = 20\n",
    "feature_subset = [\"blue_mean\", \"red_mean\", \"green_mean\", \"red_var\", \"blue_var\", \"green_var\", \"hist_lab_bin0.95\"]\n",
    "for _, row in df_supp_loadings.iterrows():\n",
    "    load_x = row[\"Dim1\"]\n",
    "    load_y = row[\"Dim2\"]\n",
    "    feature = row[\"feature\"]\n",
    "    if isinstance(feature, str) and not any(term in feature for term in feature_subset):\n",
    "        continue\n",
    "    ax.arrow(0, 0, load_x*amod, load_y*amod, color=\"black\", alpha=1, width=0.1, head_width=0.5, length_includes_head=True, zorder=4)\n",
    "    ax.text(load_x*amod, load_y*amod, str(feature)[5:], color=\"black\", fontsize=8, zorder=5,\n",
    "            # bbox=dict(facecolor=\"white\", alpha=1, edgecolor=\"black\", linewidth=0.5, boxstyle=\"Round\"),\n",
    "            ha='right' if load_x < 0 else 'left', va='bottom' if load_y < 0 else 'top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25b4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae944fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioencoder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
