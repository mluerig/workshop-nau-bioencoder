model:
  backbone: timm_tf_efficientnet_b5.ns_jft_in1k
  ckpt_pretrained: 
  num_classes: # in the first stage of training we don't need num_classes, since we don't have a classification head

train:
  n_epochs: &epochs 20
  amp: True
  ema: True
  ema_decay_per_epoch: 0.4 
  target_metric: precision_at_1
  stage: first # first = Supcon, second = FC finetuning for classification

dataloaders:
  train_batch_size: 120
  valid_batch_size: 120
  num_workers: 4 

optimizer:
  name: SGD
  params:
    lr: 0.003 

scheduler:
  name: CosineAnnealingLR
  params:
    T_max: *epochs
    eta_min: 0.0003 # Make sure it is smaller than lr

criterion:
  name: 'SupCon'
  params:
    temperature: 0.1

img_size: &size 128

augmentations:
  sample_save: True
  sample_n: 10
  sample_seed: 42 
  transforms: 
    - RandomResizedCrop:
        height: *size
        width: *size 
        scale:  !!python/tuple [0.7,1]
    - Flip:
    - RandomRotate90:
    - MedianBlur:
        blur_limit: 3
        p: 0.3
    - ShiftScaleRotate:
        p: 0.4
    - OpticalDistortion:
    - GridDistortion:
    - HueSaturationValue:
